{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common stuff\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = (9, 6)\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2943 entries, 0 to 2942\n",
      "Data columns (total 2 columns):\n",
      "name       2943 non-null object\n",
      "is_male    2943 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 69.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5001 entries, 0 to 5000\n",
      "Data columns (total 2 columns):\n",
      "name       5001 non-null object\n",
      "is_male    5001 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 117.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7944 entries, 0 to 5000\n",
      "Data columns (total 2 columns):\n",
      "name       7944 non-null object\n",
      "is_male    7944 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 186.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "df_male = pd.read_csv('male.txt', sep=\",\", header=None)\n",
    "df_male.columns = [\"name\"]\n",
    "df_male['is_male'] = 1\n",
    "\n",
    "df_female = pd.read_csv('female.txt', sep=\",\", header=None)\n",
    "df_female.columns = [\"name\"]\n",
    "df_female['is_male'] = 0\n",
    "\n",
    "df = df_male.append(df_female)\n",
    "df.name = df.name.str.lower()\n",
    "\n",
    "display(df_male.info())\n",
    "display(df_female.info())\n",
    "display(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7208 entries, 0 to 5000\n",
      "Data columns (total 2 columns):\n",
      "name       7208 non-null object\n",
      "is_male    7208 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 168.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Drop all duplicate names\n",
    "\n",
    "df.drop_duplicates(subset=[\"name\"], keep=False, inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3704\n",
       "1    2062\n",
       "Name: is_male, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    926\n",
       "1    516\n",
       "Name: is_male, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make train/test split, stratified by is_male\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=123, stratify=df.is_male)\n",
    "train_df.reset_index(inplace = True, drop = True)\n",
    "test_df.reset_index(inplace = True, drop = True)\n",
    "display(pd.value_counts(train_df[\"is_male\"]))\n",
    "display(pd.value_counts(test_df[\"is_male\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "F1-measure(1): 0.50\n",
      "Accuracy(1): 0.67\n",
      "\n",
      "F1-measure(2): 0.82\n",
      "Accuracy(2): 0.84\n",
      "\n",
      "F1-measure(3): 0.86\n",
      "Accuracy(3): 0.87\n",
      "\n",
      "F1-measure(4): 0.86\n",
      "Accuracy(4): 0.87\n",
      "\n",
      "F1-measure(5): 0.78\n",
      "Accuracy(5): 0.81\n",
      "\n",
      "F1-measure(6): 0.65\n",
      "Accuracy(6): 0.74\n",
      "\n",
      "F1-measure(7): 0.53\n",
      "Accuracy(7): 0.68\n",
      "\n",
      "F1-measure(8): 0.44\n",
      "Accuracy(8): 0.66\n"
     ]
    }
   ],
   "source": [
    "# Let's use Naive Bayes to classify, we'll use CountVectorizer in char_wb mode,\n",
    "# it's same as using ngrams from nltk.util\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import *\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "for i in range(1, 9):\n",
    "    clf = Pipeline([\n",
    "        ('vect', CountVectorizer(analyzer='char_wb')),\n",
    "        ('tfidf', TfidfTransformer()),    \n",
    "        ('clf', MultinomialNB()),\n",
    "    ])\n",
    "\n",
    "    parameters = {\n",
    "        'vect__ngram_range': [(i, i)],\n",
    "        'clf__alpha': (0.001, 0.01, 0.1, 1, 2),\n",
    "        'tfidf__use_idf': (True, False)\n",
    "    }\n",
    "\n",
    "    clf = GridSearchCV(clf, parameters, scoring='f1', cv=5, n_jobs=-1)\n",
    "\n",
    "    clf.fit(train_df.name, train_df.is_male)\n",
    "    \n",
    "    predictions = clf.best_estimator_.predict(test_df.name)\n",
    "\n",
    "    print(\"\\nF1-measure(%d): %.2f\" % (i, f1_score(test_df.is_male, predictions, average='macro')))\n",
    "    print(\"Accuracy(%d): %.2f\" % (i, accuracy_score(test_df.is_male, predictions)))  \n",
    "    \n",
    "# As we can see, 3 and 4-grams give the best results, that's because when n-gram length is too short\n",
    "# there's not much info about the name for classifier to capture, i.e. it's underfit.\n",
    "# When n-gram is too long, it captures too many info, i.e. it's overfit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5766 entries, 0 to 5765\n",
      "Data columns (total 2 columns):\n",
      "name       5766 non-null object\n",
      "is_male    5766 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 135.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num chars 29\n",
      "Max len 15\n",
      "(5766, 15, 29)\n",
      "[False False False  True False False False False False False False False\n",
      " False False False False False False False False False False False False\n",
      " False False False False False]\n"
     ]
    }
   ],
   "source": [
    "# Let's use neural network to solve this\n",
    "\n",
    "display(train_df.info())\n",
    "\n",
    "chars = sorted(list(set(\"\".join(train_df.name))))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "\n",
    "# All english letters + 3 punct chars\n",
    "print(\"Num chars\", len(chars))\n",
    "\n",
    "# Let's cheat a bit and find out maxlen for all dataset, not just train, it'll just\n",
    "# make our code easier, we could have just made it maxlen_train * 1.5 or something\n",
    "# like that\n",
    "maxlen = df.name.str.len().max()\n",
    "print(\"Max len\", maxlen)\n",
    "\n",
    "x = np.zeros((len(train_df), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(train_df), 1), dtype=np.bool)\n",
    "for i in range(len(train_df)):    \n",
    "    for t, char in enumerate(train_df.name[i]):        \n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i] = train_df.is_male[i]\n",
    "print(x.shape)\n",
    "print(x[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating RNN(N=16,D=0.10,Bi=0,Ep=60)\n",
      "CPU times: user 1min 10s, sys: 10.3 s, total: 1min 20s\n",
      "Wall time: 19.8 s\n",
      "\n",
      "Calculating RNN(N=16,D=0.10,Bi=1,Ep=60)\n",
      "CPU times: user 4min 59s, sys: 23.4 s, total: 5min 23s\n",
      "Wall time: 55.3 s\n",
      "\n",
      "Calculating RNN(N=128,D=0.10,Bi=0,Ep=60)\n",
      "CPU times: user 5min 31s, sys: 15.9 s, total: 5min 47s\n",
      "Wall time: 1min 6s\n",
      "\n",
      "Calculating RNN(N=128,D=0.10,Bi=1,Ep=60)\n",
      "CPU times: user 44min 26s, sys: 1min 59s, total: 46min 25s\n",
      "Wall time: 6min 51s\n",
      "\n",
      "Calculating RNN(N=16,D=0.30,Bi=0,Ep=60)\n",
      "CPU times: user 1min 14s, sys: 10.4 s, total: 1min 25s\n",
      "Wall time: 21 s\n",
      "\n",
      "Calculating RNN(N=16,D=0.30,Bi=1,Ep=60)\n",
      "CPU times: user 5min 4s, sys: 24 s, total: 5min 28s\n",
      "Wall time: 1min\n",
      "\n",
      "Calculating RNN(N=128,D=0.30,Bi=0,Ep=60)\n",
      "CPU times: user 5min 34s, sys: 14 s, total: 5min 47s\n",
      "Wall time: 1min 10s\n",
      "\n",
      "Calculating RNN(N=128,D=0.30,Bi=1,Ep=60)\n",
      "CPU times: user 45min 21s, sys: 2min 3s, total: 47min 25s\n",
      "Wall time: 7min 22s\n",
      "\n",
      "\n",
      "F1-measure(RNN(N=16,D=0.10,Bi=0,Ep=60)): 0.83\n",
      "Accuracy(RNN(N=16,D=0.10,Bi=0,Ep=60)): 0.85\n",
      "\n",
      "F1-measure(RNN(N=16,D=0.10,Bi=1,Ep=60)): 0.86\n",
      "Accuracy(RNN(N=16,D=0.10,Bi=1,Ep=60)): 0.87\n",
      "\n",
      "F1-measure(RNN(N=128,D=0.10,Bi=0,Ep=60)): 0.88\n",
      "Accuracy(RNN(N=128,D=0.10,Bi=0,Ep=60)): 0.89\n",
      "\n",
      "F1-measure(RNN(N=128,D=0.10,Bi=1,Ep=60)): 0.85\n",
      "Accuracy(RNN(N=128,D=0.10,Bi=1,Ep=60)): 0.86\n",
      "\n",
      "F1-measure(RNN(N=16,D=0.30,Bi=0,Ep=60)): 0.84\n",
      "Accuracy(RNN(N=16,D=0.30,Bi=0,Ep=60)): 0.85\n",
      "\n",
      "F1-measure(RNN(N=16,D=0.30,Bi=1,Ep=60)): 0.86\n",
      "Accuracy(RNN(N=16,D=0.30,Bi=1,Ep=60)): 0.88\n",
      "\n",
      "F1-measure(RNN(N=128,D=0.30,Bi=0,Ep=60)): 0.87\n",
      "Accuracy(RNN(N=128,D=0.30,Bi=0,Ep=60)): 0.88\n",
      "\n",
      "F1-measure(RNN(N=128,D=0.30,Bi=1,Ep=60)): 0.87\n",
      "Accuracy(RNN(N=128,D=0.30,Bi=1,Ep=60)): 0.88\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Bidirectional\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def gen_val_rnn(num_neurons, dropout_val, is_bidir, num_epochs):    \n",
    "    descr = \"RNN(N=%d,D=%.2f,Bi=%d,Ep=%d)\" % (num_neurons, dropout_val, is_bidir, num_epochs)\n",
    "    print(\"\\nCalculating\", descr)\n",
    "    model = Sequential()\n",
    "    if is_bidir:\n",
    "        model.add(Bidirectional(LSTM(num_neurons, return_sequences=True),\n",
    "            input_shape=(maxlen, len(chars))))\n",
    "        model.add(Bidirectional(LSTM(num_neurons)))\n",
    "    else:\n",
    "        model.add(LSTM(num_neurons, input_shape=(maxlen, len(chars))))\n",
    "    model.add(Dropout(dropout_val))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    optimizer = RMSprop(lr=0.01)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    #for iteration in range(0, num_epochs):\n",
    "        #print()\n",
    "        #print('-' * 50)\n",
    "        #print('Iteration', iteration)\n",
    "    model.fit(x, to_categorical(y, 2), batch_size=128, epochs=num_epochs, validation_split=0.1, verbose=0)\n",
    "        \n",
    "    x_test = np.zeros((len(test_df), maxlen, len(chars)), dtype=np.bool)\n",
    "    for i in range(len(test_df)):    \n",
    "        for t, char in enumerate(test_df.name[i]):        \n",
    "            x_test[i, t, char_indices[char]] = 1    \n",
    "    y_pred = model.predict_classes(x_test)\n",
    "    \n",
    "    score_f1 = f1_score(test_df.is_male, y_pred, average='macro')\n",
    "    score_acc = accuracy_score(test_df.is_male, y_pred)        \n",
    "        \n",
    "    return (descr, score_f1, score_acc)\n",
    "\n",
    "scores = []\n",
    "    \n",
    "%time scores.append(gen_val_rnn(16, 0.1, False, 60))\n",
    "%time scores.append(gen_val_rnn(16, 0.1, True, 60))\n",
    "%time scores.append(gen_val_rnn(128, 0.1, False, 60))\n",
    "%time scores.append(gen_val_rnn(128, 0.1, True, 60))\n",
    "%time scores.append(gen_val_rnn(16, 0.3, False, 60))\n",
    "%time scores.append(gen_val_rnn(16, 0.3, True, 60))\n",
    "%time scores.append(gen_val_rnn(128, 0.3, False, 60))\n",
    "%time scores.append(gen_val_rnn(128, 0.3, True, 60))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "for s in scores:\n",
    "    print(\"F1-measure(%s): %.2f\" % (s[0], s[1]))\n",
    "    print(\"Accuracy(%s): %.2f\\n\" % (s[0], s[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like the best is RNN(N=128,D=0.10,Bi=0,Ep=60), generally, the more neurons the better\n",
    "# more complex network architecture doesn't give us any gain, m.b. it's because\n",
    "# there's not too much information in separate letters and letter sequences in human names. i.e.\n",
    "# there're not much \"features\" that network can deduce."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
